### 1. Ways to implement distributed lock

> 不管是jvm锁还是mysql锁，为了保证线程的并发安全，都提供了悲观独占排他锁。所以**独占排他**也是分布式锁的基本要求
>
> 1. 基于mysql关系型实现
> 2. 基于redis非关系型数据实现 
> 3. 基于zookeeper实现

### 2. Case of distributed system issue

> 在集群情况下会,库存在并发量较大情况下很容易发生超卖现象，一旦发生超卖现象，就会出现多成交了订单而发不了货的情况。 场景:商品S库存余量为5时，用户A和B同时来购买一个商品S，此时查询库存数都为5，库存充足则开始 减库存:
>
> 用户A:update db_stock set stock = stock - 1 where id = 1 
>
> 用户B:update db_stock set stock = stock - 1 where id = 1 
>
> 并发情况下，更新后的结果可能是4，而实际的最终库存量应该是3才对

### 3. Mysql 悲观锁，乐观锁

> 1. **悲观锁（Pessimistic Locking）**
>
>    在**SELECT** **的读取锁定主要分为两种方式:**
>
>    SELECT ... LOCK IN SHARE MODE (共享锁)， 在有一方事务要Update 同一个表单时很容易造成死锁
>
>     SELECT ... FOR UPDATE (悲观锁)
>
>    这两种方式在事务(Transaction) 进行当中SELECT 到同一个数据表时，都必须等待其它事务数据被提交 (Commit)后才会执行。
>
>    简单的说，如果SELECT 后面若要UPDATE 同一个表单，最好使用SELECT ... FOR UPDATE
>
> 2. **乐观锁（Optimistic Locking）**
>
>    乐观锁假设认为数据一般情况下不会造成冲突，所 以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则重试。使用数据版本(Version)记录机制实现，这是乐观锁最常用的实现 方式。当读取数据时，将version字段的值一同读出，数据每更新一 次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录 的当前版本信息与第一次取 出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新。

### 4. 基于**MySql**实现分布式锁

> 
>
>    1. 线程同时获取锁(insert)
>    2. 获取成功，执行业务逻辑，执行完成释放锁(delete)
>    3. 其他线程等待重试
>
>    **缺点**:
>
>    1. 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 
>
>       解决方案:给 锁数据库 搭建主备
>
>    2. 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得 到锁。
>
>        解决方案:只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。
>
>    3. 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在 了。
>
>        解决方案:记录获取锁的主机信息和线程信息，如果相同线程要获取锁，直接重入。
>
>    4. 受制于数据库性能，并发能力有限。
>
>       解决方案:无法解决。
>       
### 5. 基于**redis** **实现分布式锁** （Redisson常用）
>
>   借助于redis中的命令setnx(key, value)，key不存在就新增，存在就什么都不做。同时有多个客户端发 送setnx命令，只有一个客户端可以成功，返回1(true);其他的客户端返回0(false)。
>
>   1. 多个客户端同时获取锁(setnx)
>   2. 获取成功，执行业务逻辑，执行完成释放锁(del) 
>   3.  其他客户端等待重试。
>
>   **常出现问题**
>
>   1. 问题：dead lock(setnx刚好获取到锁，服务器宕机，无法del, 导致死锁), 给锁设置过期时间，自动释放锁。
>
>      **设置过期锁时间两种方式:**
>
>      1. 通过expire设置过期时间(缺乏原子性:如果在setnx和expire之间出现异常，锁也无法释放) 
>      2. 使用set指令设置过期时间:set key value ex 3 nx(既达到setnx的效果，又设置了过期时间)
>
>   2. 问题: 可能会释放其他服务器的锁。 场景:如果业务逻辑的执行时间是7s。执行流程如下
>
>      1. index1业务逻辑没执行完，3秒后锁被自动释放。
>      2. index2获取到锁，执行业务逻辑，3秒后锁被自动释放。
>      3. index3获取到锁，执行业务逻辑
>      4. index1业务逻辑执行完成，开始调用del释放锁，这时释放的是index3的锁，导致index3的业务执行1s就被别人释放。
>
>      最终等于没锁的情况。解决:setnx获取锁时，设置一个指定的唯一值(例如:uuid);释放前获取这个值，判断是否自己的锁。
>
>   3. 问题：基于问题2， 删除操作缺乏原子性。
>
>      场景:
>
>      1. index1执行删除时，查询到的lock值确实和uuid相等
>      2. index1执行删除前，lock刚好过期时间已到，被redis自动释放 3. index2获取了lock
>      3. index1执行删除，此时会把index2的lock删除
>
>      解决方案:没有一个命令可以同时做到判断 + 删除，所有只能通过其他方式实现(**LUA脚本**)
>
>   4. 问题：lua加锁命令使用了 SETNX ，一旦键存在就无法再设置成功，这就导致后续同一线程内继续加 锁，将会加锁失败。
>
>      可重入性就可以解决这个尴尬的问题，当线程拥有锁之后，往后再遇到加锁方法，直接将加锁次数加 1，然后再执行方法逻辑。退出加锁方法之后，加锁次数再减 1，当加锁次数为 0 时，锁才被真正的释 放。
>
>      解决方案:redis + Hash
>
>   5. 问题：redis集群状态下锁失效
>
>      解决方案：**红锁算法**
>
> 
>
### 6. 基于Zookeeper实现分布式锁
>
>Zookeeper(业界简称zk)是一种提供配置管理、分布式协同以及命名的中心化服务。
>
>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.
>
>Zookeeper提供一个多层级的节点命名空间(节点称为znode)，每个节点都用一个以斜杠(/)分隔的 路径表示，而且每个节点都有父节点(根节点除外)，非常类似于文件系统。并且每个节点都是唯一 的.
>
>znode节点有四种类型:
>
>**PERSISTENT**:永久节点。客户端与zookeeper断开连接后，该节点依旧存在 
>
>**EPHEMERAL**:临时节点。客户端与zookeeper断开连接后，该节点被删除 
>
>**PERSISTENT_SEQUENTIAL**:永久节点、序列化。客户端与zookeeper断开连接后，该节点依旧 存在，只是Zookeeper给该节点名称进行顺序编号 
>
>**EPHEMERAL_SEQUENTIAL**:临时节点、序列化。客户端与zookeeper断开连接后，该节点被删 除，只是Zookeeper给该节点名称进行顺序编号
>
>事件监听:在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper 会通知客户端。当前zookeeper有如下四种事件:
>
>1. 节点创建
>2. 节点删除
>3. 节点数据修改
>4. 子节点变更
>
>
>
>分布式锁的步骤:
>
>1. 获取锁:create一个节点
>2. 删除锁:delete一个节点
>3. 重试:没有获取到锁的请求重试
>
>参照redis分布式锁的特点:
>
>1. 互斥 排他
>2. 防死锁:
>  1. 可自动释放锁(临时节点) :获得锁之后客户端所在机器宕机了，客户端没有主动删除子节 点;如果创建的是永久的节点，那么这个锁永远不会释放，导致死锁;由于创建的是临时节 点，客户端宕机后，过了一定时间zookeeper没有收到客户端的心跳包判断会话失效，将临 时节点删除从而释放锁。
>  2. 可重入锁:借助于ThreadLocal
>3. 防误删:宕机自动释放临时节点，不需要设置过期时间，也就不存在误删问题。
>4. 加锁/解锁要具备原子性
>5. 单点问题:使用Zookeeper可以有效的解决单点问题，ZK一般是集群部署的。
>6. 集群问题:zookeeper集群是强一致性的，只要集群中有半数以上的机器存活，就可以对外提供服 务
>
>**实现思路**:
>
>1. 多个请求同时添加一个相同的临时节点，只有一个可以添加成功。添加成功的获取到锁 
>2. 执行业务逻辑完成业务流程后，删除节点释放锁。
>
>**优化1: 临时序列化节点 + 阻塞**
>
>​	上锁过程中，如果使用无限自旋会严重影响性能，每个请求要想正常的执行完成，最终都是要创建节点，如果能够避免争抢必然	可以提高性能。 这里借助于zk的**临时序列化节点**，实现分布式锁， 每个请求直接创建临时序列化节点，序号最小获取锁。
>
>​	缺点：原因:虽然不用反复争抢创建节点了，但是会自选判断自己是最小的节点，这个判断逻辑反而更复杂更耗时
>
>**优化2:  监听实现阻塞锁**
>
>假如当前有1000个节点在等待锁，如果获得锁的客户端释放锁时，这 1000个客户端都会被唤醒，这种情况称为“羊群效应”;在这种羊群效应中，zookeeper需要通知1000个 客户端，这会阻塞其他的操作，最好的情况应该只唤醒新的最小节点对应的客户端。应该怎么做呢?在 设置事件监听时，每个客户端应该对刚好在它之前的子节点设置事件监听，例如子节点列表 为/lock/lock-0000000000、/lock/lock-0000000001、/lock/lock-0000000002，序号为1的客户端监听 序号为0的子节点删除消息，序号为2的监听序号为1的子节点删除消息。
>
>​	**所以调整后的分布式锁算法流程如下:**
>
>1. 客户端连接zookeeper，并在/lock下创建临时的且有序的子节点，第一个客户端对应的子节点 为/lock/lock-0000000000，	第二个为/lock/lock-0000000001，以此类推; 
>2. 客户端获取/lock下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子 节点，如果是则认为获得锁，**否则监听刚好在自己之前一位的子节点删除消息**，获得子节点变更通 知后重复此步骤直至获得锁;
>3. 执行业务代码;
>4. 完成业务流程后，删除对应的子节点释放锁。
>
>**优化3: 可重入锁， 使用ThreadLocal**
>
>
>
>参照redis分布式锁的特点:
>
>1. 互斥 排他:zk节点的不可重复性，以及序列化节点的有序性
>2. 防死锁:
>   1. 可自动释放锁:临时节点
>   2. 可重入锁:借助于ThreadLocal
>3. 防误删:临时节点
>4. 加锁/解锁要具备原子性
>5. 单点问题:使用Zookeeper可以有效的解决单点问题，ZK一般是集群部署的。
>6. 集群问题:zookeeper集群是强一致性的，只要集群中有半数以上的机器存活，就可以对外提供服 务。
>7. 公平锁:有序性节点
>
>**目前市场使用curator，是netflix公司开源的一套zookeeper客户端**





