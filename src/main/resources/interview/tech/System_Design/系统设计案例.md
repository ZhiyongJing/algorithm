### 1. Tiny URL 

> **Functional requirement: **
>
> > - Given a URL, service will generate a unique and shorter url
> > - When user click on the shorter url, our service will return original URL and redirect to the original link
> > - Tiny URL will be expired within a time period
> > - User may be able to customized a short URL
> > - Deleter URL
>
> **Non-Function requeirment:**
>
> > - Availiblity: The system should be high availability, otherwise Tiny URL redirections will be failed
> > - Scalability: System can be horizontally scalable by following CAP theorem 
> > - Latency: Redirection should happen in real-tim with mimium latency 
> > - Tiny URL should not be predicatable 
> > - Read heavy service
>
> **Extended requirement:**
>
> > The service should be accessed through RESTful API. 
> >
> > - Based on senario of when, where, how it happens
> > - Based on how easy to implement the service
>
> **Capacity Estimation and Constraints**
>
> > how many users we have? 
> > Let’s assuem we have 200M users.  let’s suppose each user will  generate 0.1 URL per day， redirected by 10 URLs/day
> >
> > - Write QPS
> >   - Average: 200,000,000* 0.1 / (24*3600) = 231.4 QPS , Let’s say 300 QPS
> >   - Peak: 300*2 = 600 QPS 
> > - Read QPS (100 times of write)
> >   - Average: 30K QPS
> >   - Peak: 60K QPS
> > - Storage(WRITE)
> >   - 500 byte for every url, 200,000,000* 0.1* 0.5 KB= 10,000,000 KB = 10000 MB = 10 GB / DAY
> >   - 10 TB distk can use 3 years, if we store 5 years, we need 20TB including backup
> > - Memory(READ)
> >   - Let’s follow 8/2 rule, means 20% of URLs taking 80% traffic, and we can cache 20% URLs per day
> >   - Every day, we need 200M * 0.5 KB* 10 *0.2 = 200,000,000 KB = 200GB /DAY
>
> **Service:**
>
> > - Functions
> >
> >   - Create Tiny URL
> >     `createURL(APIKey, userId, originalURL, customize_alias = None, expire_data = 5 years)`
> >
> >     API key can prevent abuse, and 
> >
> >   - Return original URL
> >
> >     `redirectURL(userId, tinyURL)`
> >
> >   - Delete Tiny URL
> >
> >     `deleteURL(userId, tinyURL)`
> >
> > - RESTful API
> >
> >   - GET /<tiny_url>
> >   - POST /tiny_url
> >     - Payload: {……) 
> >     - Return: short url
> >
> > **How do we detect and prevent abuse?** 
> > For instance, any service can put us out of business by consuming all our keys in the current design. To prevent abuse, we can limit users through their APIKey, how many URL they can create or access in a certain time.
>
> **Database:**
>
> > - SQL VS NonSQL
> >
> >   >  Since we are likely going to store billions of rows and we don’t need to use relationships between objects – a NoSQL key-value store like Dynamo or Cassandra is a better choice, which would also be easier to scale.
> >
> > - Schema
> >
> >   - user
> >
> >     > user_id: int PK
> >     >
> >     > user_name: varcher(50)
> >     >
> >     > email: varcher(50)
> >
> >   - url
> >
> >     > tiny_url: varchar(20) PK
> >     >
> >     > original_url: varcher(500) 
> >     >
> >     > expire_data: datatime 
> >
> >   - map(no join in nosql server)
> >
> >     > tiny_url: varchar(20) PK
> >     >
> >     > user_id: int 
>
> **Component Detail Design:**
>
> > 1. Encoding original url to tiny url
> >
> > > - **Option1**: user MD5, and only pick last of first 6 charters
> > >
> > >   - Pro: fast
> > >   - con: hash collisions, can not guartee unique
> > >
> > > - **Option2**: Sequential id  + base36 ([a-z ,0-9]) or base62 ([A-Z, a-z, 0-9]), if we add ‘-’ and ‘.’, we can use base64 encoding
> > >
> > >   > **Question1:** 
> > >   >
> > >   > We have the following couple of problems with our encoding scheme:
> > >   >
> > >   > 1. If multiple users enter the same URL, they can get the same shortened URL, which is not acceptable?
> > >   >
> > >   > 2. What if parts of the URL are URL-encoded? e.g., http://distributed.php?id=design, and http://distributed.php%3Fid%3Ddesign are identical except for the URL encoding
> > >   >
> > >   > **Solution:** 
> > >   >
> > >   > 1. use the Sql DB  auto incretement id feature
> > >   > 2. use the userId append to the input URLs, if user not sign in , might be a problem.
> > >
> > > - **Option3: **Generating keys offline(KGS).  
> > >   We can have a standalone Key Generation Service (KGS) that generates random six letter strings beforehand and stores them in a database (let’s call it key-DB). Whenever we want to shorten a URL, we will just take one of the already generated keys and use it. This approach will make things quite simple and fast since we will not be encoding the URL or worrying about duplications or collisions.
> > >
> > >   > **Question1:**
> > >   >
> > >   > Can concurrency cause problems?
> > >   >
> > >   > **Solution:**
> > >   >
> > >   > 1. Two tables, one for not used key, another for used key. If key is ued, moved it; Or, use flag to show key is used or not
> > >   > 2. Cache some unused key in memory, and mark them as used
> > >   > 3. Distributed lock if we have multiple web server
> > >
> > >   > **Question2:****
> > >   >
> > >   > Isn’t KGS the single point of failure?
> > >   >
> > >   > **Solution:**
> > >   >
> > >   > we can have a standby replica of KGS, and whenever the primary server dies, it can take over to generate and provide keys.
> > >
> > >   > **Question3:**
> > >   >
> > >   > user redirection use 301 or 302?
> > >   >
> > >   > **Solution**
> > >   >
> > >   > use 302. 用户第一次访问某个短链接后，如果服务器返回301状态码，则这个用户在后续多次访问统一短链接，浏览器会直接请求跳转地址，而不是短链接地址，这样一来服务器端就无法收到用户的请求。
> > >   >
> > >   > 如果服务器返回302状态码，且告知浏览器不缓存短链接请求，那么用户每次访问短链接，都会先去短链接服务端取回长链接地址，然后在跳转。
> > >   >
> > >   > 1. 从语义上来说，301跳转更为合适，因为是永久跳转，不会每次都访问服务端，还可以减小服务端压力。
> > >   > 2. 但如果使用301跳转，服务端就无法精确搜集用户的访问行为了。
> > >   > 3. 相反302跳转会导致服务端压力增大，但服务端此时就可精确搜集用户的访问行为。基于用户的访问行为，可以做一些分析，得出一些有意思的结论。比如可以根据用户IP地址得出用户区域分布情况，根据User-Agent消息头分析出用户使用不同的操作系统以及浏览器比例等等。
>
> **Scalability**
>
> > 1. **DB**
> >
> >    - Sharing
> >      - **Range Based Partitioning: **We can store **tiny URLs** in separate partitions based on the first letter of the URL or the hash key. Hence we save all the URLs starting with letter ‘A’ in one partition and those that start with letter ‘B’ into another partition and so on. This approach is called range based partitioning.   **May cause some overload partitions **, need to Monitor it or use consistanc hashing.
> >      - **Hash Function: **In our case, we can take the hash of the ‘key’ or the actual URL to determine the partition to store the file. **May cause some overload partitions **.
> >
> >    - **Replica**
> >
> >      > KGS can have read/write spliting, once write server is done, use read server as master
> >      >
> >    
> > 2. **Cache**
> >
> >    > - **Where we use**:
> >    >
> >    >   >  Use cache between app server and db, app server and kgs.
> >    >
> >    > - **How much we need**
> >    >
> >    >   > As estimated above we need 200GB memory to cache 20% of daily traffic since a modern day server can have 256GB memory, we can easily fit all the cache into one machine, or we can choose to use a couple of smaller servers to store all these hot URLs.
> >    >
> >    > - **Cache policy**
> >    >
> >    >   > Read-through
> >    >   > Write-through
> >    >
> >    > - **Cache eviction policy**
> >    >
> >    >   > Least Recently Used (LRU) can be a reasonable policy for our system. 
> >    >   
> >    > - **Cache replica**
> >    >
> >    >   > When we can not find url, we will go to the db. database. Whenever this happens, we can update the cache and pass the new entry to all the cache replicas. Each replica can update their cache by adding the new entry. If a replica already has that entry, it can simply ignore it.
> >    >
> >
> > 3. **Load Balancer (LB)**
> >
> >    > - **Where we use**:
> >    >
> >    >   > 1. Between Clients and Application servers
> >    >   > 2. Between Application Servers and database servers
> >    >   > 3. Between Application Servers and Cache servers
> >    >
> >    > - **Distribution strategy**
> >    >
> >    >   > 1. Round-robin
> >    >   > 2. **least_conn**, use this one to avoid case that If a server is overloaded or slow
> >
>

### 2. Vending Machine ?

> design software for vending machines sold Amazon Kindles
>
> **Functional requirement: **
>
> > - User login/register
> > - User are able to search a kindle
> > - User are able to browser kindels with/without conditions
> > - User are able to make order on kindles and make a payment
> > - USer are able to track the shippment
>
> **Non-Function requeirment:**
>
> > - Availiblity: 
> > - Scalability: 
> > - Performance: latency, throughput
> > - Security
>
> **Extended requirement:**
>
> > - User are able to return the kindle?
>
> **Capacity Estimation and Constraints**
>
> > how many users we have? 
> > Let’s assuem we have 200M users.  let’s suppose each user will  generate 0.1 URL per day， redirected by 10 URLs/day
> >
> > - Write QPS
> >   - Average: 200,000,000* 0.1 / (24*3600) = 231.4 QPS , Let’s say 300 QPS
> >   - Peak: 300*2 = 600 QPS 
> > - Read QPS (100 times of write)
> >   - Average: 30K QPS
> >   - Peak: 60K QPS
> > - Storage(WRITE)
> >   - 500 byte for every url, 200,000,000* 0.1* 0.5 KB= 10,000,000 KB = 10000 MB = 10 GB / DAY
> >   - 10 TB distk can use 3 years, if we store 5 years, we need 20TB including backup
> > - Memory(READ)
> >   - Let’s follow 8/2 rule, means 20% of URLs taking 80% traffic, and we can cache 20% URLs per day
> >   - Every day, we need 200M * 0.5 KB* 10 *0.2 = 200,000,000 KB = 200GB /DAY
>
> **Service:**
>
> > - Functions
> >
> > - RESTful API
> >
> > **How do we detect and prevent abuse?** 
> > For instance, any service can put us out of business by consuming all our keys in the current design. To prevent abuse, we can limit users through their APIKey, how many URL they can create or access in a certain time.
>
> **Database:**
>
> > 
>
> **Component Detail Design:**
>
> > - 
>
> **Scalability**
>
> > 

### 3.  Design Amazon Lockers

> Functional requirement: **
>
> > - Customers are able to find list of lockers based on the locations for package delivery.
> > - Customres should be able to track the status of their package and receive notifications when it's ready for pickup.
> > - Customrers should be able to  retrieve their package securely, upon arrival at the locker location, .
> > - Deliveryman should be able to securely place packages into designated lockers.
> > - 
>
> **Non-Function requeirment:**
>
> > - **Scalability**: The system should be scalable to handle a large number of users and packages, especially during peak times.
> > - **Availiblity**: high availability to ensure users can access lockers and retrieve their packages at any time.
> > - **Performance**: latency, throughput. It should provide fast response times for package pickup and notification delivery.
> > - **Security**:Security measures should be implemented to protect user identity and package integrity.
>
> **Extended requirement:**
>
> > - 
>
> **Capacity Estimation and Constraints**
>
> > how many users we have? 
> > Let’s assuem we have 200M users.  let’s suppose 10% will use Amazon locker,  only 0.1 per each day, means a user use 0.01 Amzone lockers.
> >
> > - Write QPS
> >   - Average: 200,000,000* 0.1 * 0.1 * / (24*3600) = 23.14 QPS , Let’s say 30 QPS
> >   - Peak: 20*2 = 60 QPS 
> > - Read QPS（10 times of write）
> >   - Average: 300 QPS
> >   - Peak: 600 QPS
> > - Storage(WRITE)
> >   - 100 byte for every record, 30 * 86400 * 0.1 KB= 259,200 KB = 260 MB = 0.26 GB / DAY
> >   - 260GB distk can use 3 years
> > - Memory(READ)
> >   - Let’s follow 8/2 rule, means 20% of data taking 80% traffic, and we can cache 20% data per day
> >   - Every day, we need 300 * 86400 * 0.1KB * 0.2 =  0.52GB /DAY
>
> **Service:**
>
> > - Authentication service
> > - Notification service: notic customer once the package is ready for pickup
> > - Package tracking service
> > - Locker service
> >   - searchLockers(apiKey, userInfo, order, location)
> >   - bookLockers(apiKey, userInfo, order,  locker)
> >   - updateLockers(apiKey, userInfo, order,  locker) may not need
> >
> > - Code gerneration service
> >   - generateCode(apiKey, userInfo, order, locker)
> >   - validateCode(lockerStation, code)
> >   - closeLocer(apiKey, userInfo,  locker)
> >
> >
> > **How do we detect and prevent abuse?** 
> > For instance, any service can put us out of business by consuming all our keys in the current design. To prevent abuse, we can limit users through their APIKey.
>
> **Database:**
>
> > - SQL vs Nosql
> >
> >   > ACID requied
> >   >
> >   > less data
> >
> > - Schema
> >
> >   > - Locker:
> >   >
> >   >   > locker_id:  (Primary Key)
> >   >   >
> >   >   > location: varchar
> >   >   >
> >   >   > capacity: varchar
> >   >   >
> >   >   > availability boolean
> >   >
> >   > - Code
> >   >
> >   >   > code_id: int PK
> >   >   >
> >   >   > order_id: int 
> >   >   >
> >   >   > locker_id: int 
>
> **Component Detail Design:**
>
> > use unique order id to generate the code
>
> **Scalability**
>
> > - Database Replication:  Single leader replication read/write spliting 
> > - Cache redis 
>

### 4.  Typeahead Suggestion

> **Typeahead suggestions enable users to search for known and frequently searched terms. As the user types into the search box, it tries to predict the query based on the characters the user has entered and gives a list of suggestion to complete the query. Typeahead suggestions help user to articulate their search queries better. It’s not about speeding up the search process but rather about guiding the users and lending them a helping hand in constructing their search query.**
>
> **Functional requirement: **
>
> > - When login user type the characters, the system will return the top 10th items based on his history
> >
> > - When unloginc user type the characters, the system will retrun the top 10th items based on the golbal search time.
> >
> > - We should log the user’s queries, and track them to update the trie structure offline
> >
> >   - Option1: We can make a copy of the trie on each server to update it offline. Once done we can switch to start using it and discard the old one.
> >
> >   - Option2:  We can have a master-slave configuration for each trie server. We can update slave
> >
> >     while the master is serving traffic. Once the update is complete, we can make the slave our new
> >
> >     master. We can later update our old master, which can then start serving traffic too.
>
> **Non-Function requeirment:**
>
> > - Availiblity: 
> > - Scalability: 
> > - Performance: 
> >   - latency： response time will be 20ms
> >   - throughput. 
> > - Security
>
> **Extended requirement:**
>
> > - 
>
> **Capacity Estimation and Constraints**
>
> > how many users we have? 
> > Let’s assuem we have 200M users.  let’s suppose each user will  search 1 times, and each time will type 20 characters
> >
> > - Write QPS
> >   - Average: 
> >   - Peak: 
> > - Read QPS 
> >   - Average: 200,000,000 * 1 * 20 / 24 / 3600 = 46296 = 46K QPS
> >   - Peak: 92K QPS
> > - Storage(WRITE)
> >   - 2 byte for every character, 200,000,000 * 0.002 KB * 20 = 8,000,000 KB = 8,000 MB = 8 GB / DAY
> >   -  If we assume we have 2% new queries every day and if we are maintaining our index for last one year
> >     8GB + (0.02 * 8GB * 365 days) = 66.4GB
> > - Memory(READ)
> >   - Let’s put all data into the cache
> >   - Every day, we need 200M * 0.5 KB* 10 *0.2 = 200,000,000 KB = 200GB /DAY
>
> **Service:**
>
> > - Log service
> >
> >   - use Flume + Kafaka + Spark streaming in HDFS and store data into NoSQL like Cassandra or Hbase
> >
> > - Trie service
> >
> >   > ```java
> >   > class Trie {
> >   > 
> >   >         // Trie 节点的定义
> >   >         class Node {
> >   >             boolean isWord = false;
> >   >           	double frequency;
> >   >             List<Node> children = Arrays.asList(new Node[26]);
> >   >         };
> >   >         Node Root, curr;
> >   >         // 初始化堆，按照出现频率从小到大排列
> >   >             Queue<Node> resultBuffer = new PriorityQueue<>(
> >   >                     (n1, n2) -> count.get(n2.frequency) - count.get(n1.frequency));
> >   > 
> >   >         // 运行一个深度优先搜索（DFS）在 Trie 上，从给定前缀开始，并将所有单词添加到 resultBuffer 中，限制结果大小为 10
> >   >         void dfsWithPrefix(Node curr, String word) {
> >   >             if (resultBuffer.size() == 10)
> >   >                 return;
> >   >             if (curr.isWord)
> >   >                 resultBuffer.add(word);
> >   > 
> >   >             // 在所有可能的路径上运行 DFS。
> >   >             for (char c = 'a'; c <= 'z'; c++)
> >   >                 if (curr.children.get(c - 'a') != null)
> >   >                     dfsWithPrefix(curr.children.get(c - 'a'), word + c);
> >   >         }
> >   >         Trie() {
> >   >             Root = new Node();
> >   >         }
> >   > 
> >   >         // 在 Trie 中插入字符串
> >   >         void insert(String s) {
> >   > 
> >   >             // 将 curr 指针指向 Trie 的根节点。
> >   >             curr = Root;
> >   >             for (char c : s.toCharArray()) {
> >   >                 if (curr.children.get(c - 'a') == null)
> >   >                     curr.children.set(c - 'a', new Node());
> >   >                 curr = curr.children.get(c - 'a');
> >   >             }
> >   > 
> >   >             // 将该节点标记为一个完成的单词。
> >   >             curr.isWord = true;
> >   >         }
> >   > 
> >   >         // 获取以指定前缀开头的单词
> >   >         List<String> getWordsStartingWith(String prefix) {
> >   >             curr = Root;
> >   >             resultBuffer = new ArrayList<String>();
> >   >             // 将 curr 移动到其 Trie 表示中前缀的末尾。
> >   >             for (char c : prefix.toCharArray()) {
> >   >                 if (curr.children.get(c - 'a') == null)
> >   >                     return resultBuffer;
> >   >                 curr = curr.children.get(c - 'a');
> >   >             }
> >   >             dfsWithPrefix(curr, prefix);
> >   >             return resultBuffer;
> >   >         }
> >   >     };
> >   > 
> >   > List<List<String>> suggestedProducts(String[] products, String searchWord) {
> >   >             Trie trie = new Trie();
> >   >             List<List<String>> result = new ArrayList<>();
> >   >             // 将所有单词添加到 Trie 中。
> >   >             for (String w : products)
> >   >                 trie.insert(w);
> >   >             String prefix = new String();
> >   >             for (char c : searchWord.toCharArray()) {
> >   >                 prefix += c;
> >   >                 result.add(trie.getWordsStartingWith(prefix));
> >   >             }
> >   >             return result;
> >   >         }
> >   > ```
> >
> > - RESTful API
> >
> > **How do we detect and prevent abuse?** 
> > For instance, any service can put us out of business by consuming all our keys in the current design. To prevent abuse, we can limit users through their APIKey, how many URL they can create or access in a certain time.
>
> **Database:**
>
> > - Files system: store Trie structure
> > - NoSql database used to store log.
>
> **Component Detail Design:**
>
> > - Query  service Optimize 
> >
> >   > 1. **How to optimize the search speed?**
> >   >
> >   >    - We can merge nodes that have only one branch to save storage space and search 
> >   >    - We  can store top suggestions with each node. To save the space, we can optimize our storage by storing only references of the terminal nodes rather than storing the entire
> >   >
> >   > 2. **How to update trie?**
> >   >
> >   >    - Update the slave then sync it.
> >   >
> >   >    - We can update the tire offline
> >   >    - update the frequencies of typeahead suggestions, give more weight to the latest data.
> >   >    - Update the top 10 frequesce  on node.
> >   >
> >   > 3. **What could be different ranking criteria for suggestions?** 
> >   >
> >   >    - In addition to a simple count, for terms ranking
> >   >    - we have to consider other factors too, e.g., freshness, user location, language, demographics, personal history etc.
> >
> > - Log service Optimize
> >
> >   > 1. use sprk in hdfs 
> >
> > - Frontend optimize
> >
> >   > 1. The client should only try hitting the server if the user has not pressed any key for 50ms.
> >   > 2. If the user is constantly typing, the client can cancel the in-progress requests.
> >   > 3. Initially, the client can wait until the user enters a couple of characters.
> >   > 4. Clients can pre-fetch some data from the server to save future requests.
> >   > 5. Clients can store the recent history of suggestions locally. Recent history has a very high rate of being
> >   >
> >   > reused.
> >   >
> >   > 6. Establishing an early connection with server turns out to be one of the most important factors. As
> >   >
> >   > soon as the user opens the search engine website, the client can open a connection with the server.
> >   >
> >   > So when user types in the first character, client doesn’t waste time in establishing the connection.
> >   >
> >   > 7. The server can push some part of their cache to CDNs and Internet Service Providers (ISPs) for
> >   >
> >   > efficiency.
>
> **Scalability**
>
> > - Data partition, partiton into multiple server
> >
> >   > 1. ** Range Based Partitioning**
> >   > 2. **Partition based on the maximum capacity of the server**
> >   > 3. **Partition based on the hash of the term**
> >
> > - Cache
> >
> >   > 1. We can have separate cache servers in front of the trie servers, holding most frequently searched terms and their typeahead suggestions.
> >   >2. CDN for unlogin user
> >   
> >- Replication and load balance
> > 
> >  > We should have replicas for our trie servers both for load balancing and also for fault tolerance. We also need
> >   >
> >   > a load balancer that keeps track of our data partitioning scheme and redirects traffic based on the prefixes.

### 5. Design distributed task scheduler

### 6. Design Auction System

> Design a auction system that artist can put his painting， bidder can raise the price to gaint the painting
>
> **Functional requirement: **
>
> > - Bidding system 
>
> **Non-Function requeirment:**
>
> > - Availiblity: 
> > - Scalability: 
> > - Performance: latency, throughput
> > - Security
>
> **Extended requirement:**
>
> > - 
>
> **Capacity Estimation and Constraints**
>
> > how many users we have? 
> > Let’s assuem we have 200M users.  let’s suppose each user will  generate 0.1 URL per day， redirected by 10 URLs/day
> >
> > - Write QPS
> >   - Average: 200,000,000* 0.1 / (24*3600) = 231.4 QPS , Let’s say 300 QPS
> >   - Peak: 300*2 = 600 QPS 
> > - Read QPS (100 times of write)
> >   - Average: 30K QPS
> >   - Peak: 60K QPS
> > - Storage(WRITE)
> >   - 500 byte for every url, 200,000,000* 0.1* 0.5 KB= 10,000,000 KB = 10000 MB = 10 GB / DAY
> >   - 10 TB distk can use 3 years, if we store 5 years, we need 20TB including backup
> > - Memory(READ)
> >   - Let’s follow 8/2 rule, means 20% of URLs taking 80% traffic, and we can cache 20% URLs per day
> >   - Every day, we need 200M * 0.5 KB* 10 *0.2 = 200,000,000 KB = 200GB /DAY
>
> **Service:**
>
> > - Functions
> >
> > - RESTful API
> >
> > **How do we detect and prevent abuse?** 
> > For instance, any service can put us out of business by consuming all our keys in the current design. To prevent abuse, we can limit users through their APIKey, how many URL they can create or access in a certain time.
>
> **Database:**
>
> > 
>
> **Component Detail Design:**
>
> > 
>
> **Scalability**
>
> > 

### 6. Design 订阅 System

> design是设计一个订阅系统，主要就一个use case，如果对订阅的东西有更新，需要通知相关user，得到用户许可后才能给他更新，不然就cancel他的订阅。这轮感觉答的不好，面试官在面试中也没有什么反馈，最后还剩15分钟就说问完了。有点草草了事的意思。

### 7. Design UBER

> ​    \> 第四轮system design，考的desig‍‍‌‌‌‍‌‍‌‌‍‍‌‌‍‍‍‍‌‌n uber, 主要考数据怎么存，考鱿鱼树，g了，没看uber

### 8. Design Amazon payment

> design amazon payment system

### 9. 系统设计餐厅预约

### 10. 设计一个信用卡联名program，考虑数据安全和高可用性

### 11. system design, 假设公司有很多可以监测天气的sensor分散在各地，设计一个app可以让用户查看天气

### 12. Design what’s app

### 13.  Warehouse

>    > 1M product → 1000 warehouse → customer, we want to know how many of x product in y warehouse
>     >
>     > 这个题目比较讨厌, 是个高写入低读取的系统, write: 5000/sec, read: 100/sec.
>     > db里面我是这样设计的, 然后把当前的数存算好存在缓存里面, 不过没有解决高写入低读取的问题
>     > {
>     > id,
>     > productId,
>     > warehouseId,
>     > direction(in/out),
>     > productCount,
>     > timestamp
>     > }

### 14. 设计亚马逊音乐 后台数据网站

### 15. 系统设计，优惠券

### 16. web crawler

### 17. 考的是设计一个评分系统，用户可以给视频打1到5分，然后还需要计算出每个视频的平均分数，展示出来。然后还讨论了如何搜索评分，如搜索评分为4分之上的视频。

### 18. SD类似 Twitter Timeline 但所有人都贴到同个布告栏没有follower，从10个人用到10M人用怎么scale

### 19. tictactoe的game

### 20. 设计一个系统显示一天内销售最高的10个商品 ‍‍‌‌‌‍‌‍‌‌‍‍‌‌‍‍‍‍‌

### 21. 系统设计大概是在一个商业合作系统中，每天和每月获得其中一方的劳动报酬数据。用户量限定在一个范围内，不是百万级，所以之前准备的一些scale也没用上。面试官比较喜欢聊数据流，API通信之类的。

### 22. suggestion system for shopping good, when user select one item, suggest other items user might also consider to bought

### 23. online chat system

### 24. SD 设计一个least recent play song list

> user会一直在点歌, 听歌, 要实时的返回最近听过的20首歌

### 25. 需要考虑商家上传酒店信息和用户订房间两方面）

### 26. 设计一个返现系统  类似每次成交一单 有10 % 返回给 content creator

### 27. parking garage

### 28. 设计储存和搜索log的系统

### 29.     Design a loan website, find loans for users based on their preferences, once user click on the loan link, they will be redirected to the external url

### 30. SD题目是weather monitor system of washington state. 测温度, 地图, 用户端显示.

### 31. 考系统设计，设计短时间的投票系统，























 

























---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

> **Functional requirement: **
>
> > - 
>
> **Non-Function requeirment:**
>
> > - Availiblity: 
> > - Scalability: 
> > - Performance: latency, throughput
> > - Security
>
> **Extended requirement:**
>
> > - 
>
> **Capacity Estimation and Constraints**
>
> > how many users we have? 
> > Let’s assuem we have 200M users.  let’s suppose each user will  generate 0.1 URL per day， redirected by 10 URLs/day
> >
> > - Write QPS
> >   - Average: 200,000,000* 0.1 / (24*3600) = 231.4 QPS , Let’s say 300 QPS
> >   - Peak: 300*2 = 600 QPS 
> > - Read QPS (100 times of write)
> >   - Average: 30K QPS
> >   - Peak: 60K QPS
> > - Storage(WRITE)
> >   - 500 byte for every url, 200,000,000* 0.1* 0.5 KB= 10,000,000 KB = 10000 MB = 10 GB / DAY
> >   - 10 TB distk can use 3 years, if we store 5 years, we need 20TB including backup
> > - Memory(READ)
> >   - Let’s follow 8/2 rule, means 20% of URLs taking 80% traffic, and we can cache 20% URLs per day
> >   - Every day, we need 200M * 0.5 KB* 10 *0.2 = 200,000,000 KB = 200GB /DAY
>
> **Service:**
>
> > - Functions
> >
> > - RESTful API
> >
> > **How do we detect and prevent abuse?** 
> > For instance, any service can put us out of business by consuming all our keys in the current design. To prevent abuse, we can limit users through their APIKey, how many URL they can create or access in a certain time.
>
> **Database:**
>
> > 
>
> **Component Detail Design:**
>
> > 
>
> **Scalability**
>
> > 
>

